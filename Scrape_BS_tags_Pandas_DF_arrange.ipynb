{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Specify url\n",
    "url = 'https://tiltparenting.com/schools-for-children-learning-disabilities/'\n",
    "\n",
    "# Package the request, send the request and catch the response: r\n",
    "r = requests.get(url)\n",
    "\n",
    "# Extracts the response as html: html_doc\n",
    "html_doc = r.text\n",
    "\n",
    "# create a BeautifulSoup object from the HTML: soup\n",
    "soup = BeautifulSoup(html_doc)\n",
    "\n",
    "# Print the title of Guido's webpage\n",
    "print(soup.get_text())\n",
    "\n",
    "# Find all 'a' tags (which define hyperlinks): a_tags\n",
    "a_tags = soup.find_all('a')\n",
    "\n",
    "# Print the URLs to the shell\n",
    "#for link in a_tags:\n",
    "    #print(link.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "              ################## Scrape page with varios tags and assign to DF\n",
    "\n",
    "\n",
    "# Import packages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "#df = pd.DataFrame()\n",
    "#df.columns = ['name', 'location', 'Website', 'Grades Served', 'Type of School', 'Approach to Neurodivergence', 'Neurodifferences Supported', 'Curiculum', 'School Features', 'TiLT Parent / Community Review' ]\n",
    "# Specify url\n",
    "url = 'https://tiltparenting.com/schools-for-children-learning-disabilities/'\n",
    "\n",
    "# Package the request, send the request and catch the response: r\n",
    "r = requests.get(url)\n",
    "\n",
    "# Extracts the response as html: html_doc\n",
    "html_doc = r.text\n",
    "\n",
    "# create a BeautifulSoup object from the HTML: soup\n",
    "soup = BeautifulSoup(html_doc)\n",
    "\n",
    "# Find all 'a' tags (which define hyperlinks): a_tags\n",
    "a_tags = soup.find_all('a')\n",
    "p_tags = soup.find_all('p')\n",
    "str_tags = soup.find_all('strong')\n",
    "\n",
    "text_unsorted = [] #init list\n",
    "\n",
    "# Loop over data and add to list separating with a new line\n",
    "for link in p_tags:\n",
    "    text_unsorted.append(link.get_text('\\n'))  #split scraped data with new row\n",
    "    \n",
    "df = pd.DataFrame(text_unsorted) #create dataframe from the list\n",
    "df.to_csv('schools2.csv')\n",
    "print(df)\n",
    "    \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "                    ################ Clean DF and split data with separators into rows\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Read created csv assign separator and name of col\n",
    "df = pd.read_csv('schools1.csv', sep='\\n', names=['name']) \n",
    "\n",
    "#print(df.shape)\n",
    "\n",
    "# split and explode, each sep element means will be next row in df\n",
    "s = df['name'].str.split('\\n',expand=True)\n",
    "s.to_csv('out2.csv')      \n",
    "   \n",
    "#print(s)\n",
    "             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                      ###################### Replacing values in cells (from other column to different row)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from io import StringIO\n",
    "\n",
    "file = pd.read_csv('out3.csv')\n",
    "df = pd.DataFrame(file)\n",
    "#df.columns = ['param', 'answer', 'smth']\n",
    "print(df.columns)\n",
    "\n",
    "#Replace NaN values in answer column with values from param column\n",
    "df.answer.fillna(df.param, inplace=True)\n",
    "#Check if value in 2 cols are equal: if yes move new col has \"name\" string, if no - original value\n",
    "df['ind'] = np.where( df['param'] == df['answer'] ,'name' , df['param'])\n",
    "#Remove unneeded column        \n",
    "df.drop('param', axis=1, inplace=True)\n",
    "#Rename columns\n",
    "df.columns = ['param', 'answer']\n",
    "df.to_csv('out4.csv')\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
